{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10396, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tasks_top10_mapped_parameters.pkl', 'rb') as input_file:\n",
    "    tasks_top10_mapped_parameters = pickle.load(input_file)   \n",
    "tasks_top10_mapped_parameters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build AST</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_sequence_tokens import return_tokens, rem_nested_lists,convert_int_bool_to_str,tokenize_task,tokenize_name,is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped10 = tasks_top10_mapped_parameters.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped10['has_params'] = mapped10['found_used_parameters'].apply(lambda x: is_empty(x['intersected_params']))\n",
    "mapped10['has_params'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped10['initial_ast'] = mapped10['method_description'].apply(lambda x: return_tokens(x))\n",
    "mapped10['second_ast'] = mapped10['initial_ast'].apply(lambda x: convert_int_bool_to_str(x))\n",
    "mapped10['third_ast'] = mapped10['second_ast'].apply(lambda x: rem_nested_lists(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'yum-config-manager --enable {{ item }}', 'with_items': ['rhui-REGION-rhel-server-rhscl', 'rhel-server-rhscl-6-rpms'], 'when': [\"ansible_distribution == 'RedHat' and  ansible_distribution_major_version == '6'\", \"wazuh_manager_config.cluster.disable != 'yes'\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AnsibleTask',\n",
       " 'command',\n",
       " 'yum-config-manager --enable {{ item }}',\n",
       " 'with_items',\n",
       " 'rhui-REGION-rhel-server-rhscl,rhel-server-rhscl-6-rpms',\n",
       " 'when',\n",
       " \"ansible_distribution == 'RedHat' and  ansible_distribution_major_version == '6',wazuh_manager_config.cluster.disable != 'yes'\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mapped10['method_description'][16331])\n",
    "mapped10['third_ast'][16331]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tokenize</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name_tokens = [word_tokenize(token) for token in mapped10['task_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restart', 'datadog-agent']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_name_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped10['first_tokens'] = mapped10['third_ast'].apply(lambda x: tokenize_task(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped10 = mapped10.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10 = mapped10.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_process import remove_symbols, remove_symbols_simple,flatten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10['second_tokens'] = m10['first_tokens'].apply(lambda x: remove_symbols(x))\n",
    "m10['third_tokens'] = m10['second_tokens'].apply(lambda x: flatten_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'service': {'name': 'datadog-agent', 'state': 'restarted'}, 'when': 'datadog_enabled and not ansible_check_mode and not ansible_os_family == \"Windows\"'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AnsibleTask',\n",
       " 'service',\n",
       " 'name',\n",
       " 'datadog-agent',\n",
       " 'state',\n",
       " 'restarted',\n",
       " 'when',\n",
       " 'datadog_enabled',\n",
       " 'and',\n",
       " 'not',\n",
       " 'ansible_check_mode',\n",
       " 'and',\n",
       " 'not',\n",
       " 'ansible_os_family',\n",
       " 'Windows']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m10['method_description'][0])\n",
    "m10['third_tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10['token_task_names'] = task_name_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10 = m10.drop(columns=['initial_ast', 'second_ast','first_tokens','second_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10['descr_one_string'] = m10['third_tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10396, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tasks_top10_ast_tokenization_sodalite.pkl', 'wb') as output_file:\n",
    "    pickle.dump(m10, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tasks_top10_ast_tokenization_sodalite.pkl', 'rb') as input_file:\n",
    "    mapped10_ast_token = pickle.load(input_file)   \n",
    "mapped10_ast_token.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
